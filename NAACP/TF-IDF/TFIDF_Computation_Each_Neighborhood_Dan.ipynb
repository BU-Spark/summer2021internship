{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28c21be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "from nltk.stem import PorterStemmer\r\n",
    "from collections import Counter\r\n",
    "from num2words import num2words\r\n",
    "\r\n",
    "import nltk\r\n",
    "import os\r\n",
    "import string\r\n",
    "import numpy as np\r\n",
    "import copy\r\n",
    "import pandas as pd\r\n",
    "import pickle\r\n",
    "import re\r\n",
    "import math\r\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0d86bd",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ccae854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lower_case(data):\r\n",
    "    return np.char.lower(data)\r\n",
    "\r\n",
    "def remove_stop_words(data):\r\n",
    "    stop_words = stopwords.words('english')\r\n",
    "    words = word_tokenize(str(data))\r\n",
    "    new_text = \"\"\r\n",
    "    for w in words:\r\n",
    "        if w not in stop_words and len(w) > 1:\r\n",
    "            new_text = new_text + \" \" + w\r\n",
    "    return new_text\r\n",
    "\r\n",
    "def remove_punctuation(data):\r\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\r\n",
    "    for i in range(len(symbols)):\r\n",
    "        data = np.char.replace(data, symbols[i], ' ')\r\n",
    "        data = np.char.replace(data, \"  \", \" \")\r\n",
    "    data = np.char.replace(data, ',', '')\r\n",
    "    return data\r\n",
    "\r\n",
    "def remove_apostrophe(data):\r\n",
    "    return np.char.replace(data, \"'\", \"\")\r\n",
    "\r\n",
    "def stemming(data):\r\n",
    "    stemmer= PorterStemmer()\r\n",
    "    \r\n",
    "    tokens = word_tokenize(str(data))\r\n",
    "    new_text = \"\"\r\n",
    "    for w in tokens:\r\n",
    "        new_text = new_text + \" \" + stemmer.stem(w)\r\n",
    "    return new_text\r\n",
    "\r\n",
    "def convert_numbers(data):\r\n",
    "    tokens = word_tokenize(str(data))\r\n",
    "    new_text = \"\"\r\n",
    "    for w in tokens:\r\n",
    "        try:\r\n",
    "            w = num2words(int(w))\r\n",
    "        except:\r\n",
    "            a = 0\r\n",
    "        new_text = new_text + \" \" + w\r\n",
    "    new_text = np.char.replace(new_text, \"-\", \" \")\r\n",
    "    return new_text\r\n",
    "\r\n",
    "def preprocess(data):\r\n",
    "    data = convert_lower_case(data)\r\n",
    "    data = remove_punctuation(data) #remove comma seperately\r\n",
    "    data = remove_apostrophe(data)\r\n",
    "    data = remove_stop_words(data)\r\n",
    "    data = convert_numbers(data)\r\n",
    "    # data = stemming(data)\r\n",
    "    data = remove_punctuation(data)\r\n",
    "    data = convert_numbers(data)\r\n",
    "    # data = stemming(data) #needed again as we need to stem the words\r\n",
    "    data = remove_punctuation(data) #needed again as num2word is giving few hypens and commas fourty-one\r\n",
    "    data = remove_stop_words(data) #needed again as num2word is giving stop words 101 - one hundred and one\r\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8afcdc",
   "metadata": {},
   "source": [
    "## Creating documents out of the neighborhood-separated articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcdbe619",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f72392f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Entity_Recognition/Neighborhood_Separated_Articles/2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf0f20d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dorchester</th>\n",
       "      <th>roxbury</th>\n",
       "      <th>mattapan</th>\n",
       "      <th>hyde_park</th>\n",
       "      <th>fenway</th>\n",
       "      <th>beacon_hill</th>\n",
       "      <th>downtown</th>\n",
       "      <th>south_boston</th>\n",
       "      <th>east_boston</th>\n",
       "      <th>back_bay</th>\n",
       "      <th>...</th>\n",
       "      <th>charlestown</th>\n",
       "      <th>brighton</th>\n",
       "      <th>allston</th>\n",
       "      <th>west_end</th>\n",
       "      <th>roslindale</th>\n",
       "      <th>north_end</th>\n",
       "      <th>mission_hill</th>\n",
       "      <th>harbor_islands</th>\n",
       "      <th>longwood_medical_area</th>\n",
       "      <th>west_roxbury</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('Before entering a South African prison in 19...</td>\n",
       "      <td>('n individuals who worked in finance  insuran...</td>\n",
       "      <td>('The public scrap over who will serve as the ...</td>\n",
       "      <td>('The Boston Police Department has issued a co...</td>\n",
       "      <td>('Wahlburgers  the burger joint owned by Dorch...</td>\n",
       "      <td>('Martin J  Walsh becomes the 48th mayor of Bo...</td>\n",
       "      <td>('Last week  Mayor Marty Walsh declared to the...</td>\n",
       "      <td>('The 20 year old who allegedly beat a disable...</td>\n",
       "      <td>('Saying that Massachusetts is facing “the big...</td>\n",
       "      <td>('First Night Boston almost didn’t happen this...</td>\n",
       "      <td>...</td>\n",
       "      <td>('Bright skies belie the early spring chill as...</td>\n",
       "      <td>('Boston’s new mayor  Martin J  Walsh  has rep...</td>\n",
       "      <td>('A small army of city inspectors will soon be...</td>\n",
       "      <td>('Shakespeare’s “A Midsummer Night’s Dream” se...</td>\n",
       "      <td>('Last February  Brandon John joined more than...</td>\n",
       "      <td>('When the  offered season ticket holders the ...</td>\n",
       "      <td>('They were immigrants from Iraq and India  th...</td>\n",
       "      <td>('Rain crashes down on onto the tarp  thunder ...</td>\n",
       "      <td>('no article', 'no_id')</td>\n",
       "      <td>('It’s been almost a full month since Thomas M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('A woman’s toe was bitten off during a fight ...</td>\n",
       "      <td>('Dr  Kenneth C  Edelin  whose historic 1975 m...</td>\n",
       "      <td>('In what police described as a horrific trage...</td>\n",
       "      <td>('nOn the weekend before he was to be sworn in...</td>\n",
       "      <td>('n n n    and  are expanding their burger bus...</td>\n",
       "      <td>('One bone chilling Saturday night about 11 mo...</td>\n",
       "      <td>('The Federal Reserve must take a “patient app...</td>\n",
       "      <td>('n and Michelle Wu stood side by side at the ...</td>\n",
       "      <td>('MEMPHIS — The thank yous were almost endless...</td>\n",
       "      <td>('Chances are  if you walked past the firehous...</td>\n",
       "      <td>...</td>\n",
       "      <td>('As neighbors living a world apart  they awok...</td>\n",
       "      <td>('The 26 year old Chinese entrepreneur had jus...</td>\n",
       "      <td>('n n for help  The harrowing leaps from smoky...</td>\n",
       "      <td>('nis here    the nascent organizing committee...</td>\n",
       "      <td>('Don’t ask how the sausage is made  the old s...</td>\n",
       "      <td>('As America’s most Irish American city  it co...</td>\n",
       "      <td>('Beth Israel Deaconess Medical Center said We...</td>\n",
       "      <td>('no article', 'no_id')</td>\n",
       "      <td>('no article', 'no_id')</td>\n",
       "      <td>('Mayor Martin J  Walsh’s pick for acting fire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('It’s the ideal time for a tech journalist to...</td>\n",
       "      <td>('When they go up  they form the centerpiece o...</td>\n",
       "      <td>('The fatal shooting today of a 9 year old Mat...</td>\n",
       "      <td>('Boston saw its first two homicides of 2014 o...</td>\n",
       "      <td>('Mayor Martin J  Walsh plans to set aside spa...</td>\n",
       "      <td>('nhe Boston Public Library is using three dim...</td>\n",
       "      <td>('ncooler buses  For decades  economists like ...</td>\n",
       "      <td>('Jack Conley  who grew up in South Boston and...</td>\n",
       "      <td>('Marty Walsh has turned the casino licensing ...</td>\n",
       "      <td>('Stores selling luxury goods — once modest an...</td>\n",
       "      <td>...</td>\n",
       "      <td>('When Boston firefighters pulled up to a vaca...</td>\n",
       "      <td>('It was just some children playing baseball o...</td>\n",
       "      <td>('n n for help  The harrowing leaps from smoky...</td>\n",
       "      <td>('nis here    the nascent organizing committee...</td>\n",
       "      <td>('Former Boston councilor Felix D  Arroyo  the...</td>\n",
       "      <td>('In nine days  Wegmans will open a new superm...</td>\n",
       "      <td>('The Rev  Joseph Hung Duc Tran had been ordai...</td>\n",
       "      <td>('no article', 'no_id')</td>\n",
       "      <td>('no article', 'no_id')</td>\n",
       "      <td>('His cousin would come to Children’s Hospital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('The first major snowstorm of 2014 has intens...</td>\n",
       "      <td>('Good Morning Chief Justice Ireland  Presiden...</td>\n",
       "      <td>('During a highly publicized Boston Police Dep...</td>\n",
       "      <td>('An elderly woman became Boston’s first fire ...</td>\n",
       "      <td>('By last Christmas  Frank Nunes seemed to hav...</td>\n",
       "      <td>('QUINCY — Massachusetts Democrats saw a new B...</td>\n",
       "      <td>('When Ari S  Heckman was growing up in Provid...</td>\n",
       "      <td>('Mayor Martin J  Walsh said Wednesday that he...</td>\n",
       "      <td>('Marty Walsh has turned the casino licensing ...</td>\n",
       "      <td>('A midday altercation Friday in a bustling co...</td>\n",
       "      <td>...</td>\n",
       "      <td>('Two Charlestown teenagers — a 14 year old gi...</td>\n",
       "      <td>('Boston police are asking for the public’s he...</td>\n",
       "      <td>('n n for help  The harrowing leaps from smoky...</td>\n",
       "      <td>('The first thing everyone noticed about Dawnn...</td>\n",
       "      <td>('nn the middle of evening rush hour at South ...</td>\n",
       "      <td>('n n n nThe 150 dancing  singing  and drummin...</td>\n",
       "      <td>('nLittle about the ordinary looking two famil...</td>\n",
       "      <td>('no article', 'no_id')</td>\n",
       "      <td>('no article', 'no_id')</td>\n",
       "      <td>('The  is offering 15 percent off purchases fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('One Fund Boston  which initially collected $...</td>\n",
       "      <td>('Good Morning Chief Justice Ireland  Presiden...</td>\n",
       "      <td>('At Greater Love Tabernacle Church today  mor...</td>\n",
       "      <td>('n officials in Boston want to give 4 500 mid...</td>\n",
       "      <td>('SALEM — Martha Coakley had already made the ...</td>\n",
       "      <td>('The state’s highest court has thrown out the...</td>\n",
       "      <td>('Marty Walsh had never met Arianna Huffington...</td>\n",
       "      <td>('The state’s largest gay rights organization ...</td>\n",
       "      <td>('While he may not have been a household name ...</td>\n",
       "      <td>('nn a brisk November morning in 2001  Hubert ...</td>\n",
       "      <td>...</td>\n",
       "      <td>('A Charlestown man was sentenced to up to 12 ...</td>\n",
       "      <td>('noffice  Mayor Marty Walsh has properly focu...</td>\n",
       "      <td>('Mayor Martin J  Walsh replaced on Monday the...</td>\n",
       "      <td>('Dawnn Jaffier  the 26 year old Brighton woma...</td>\n",
       "      <td>('nn the middle of evening rush hour at South ...</td>\n",
       "      <td>('“Maybe I need a psychiatrist ” says Donato F...</td>\n",
       "      <td>('For 24 years  Ellen Wade and Maureen Brodoff...</td>\n",
       "      <td>('no article', 'no_id')</td>\n",
       "      <td>('no article', 'no_id')</td>\n",
       "      <td>('A 33 year old man with a criminal record dat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          dorchester  \\\n",
       "0  ('Before entering a South African prison in 19...   \n",
       "1  ('A woman’s toe was bitten off during a fight ...   \n",
       "2  ('It’s the ideal time for a tech journalist to...   \n",
       "3  ('The first major snowstorm of 2014 has intens...   \n",
       "4  ('One Fund Boston  which initially collected $...   \n",
       "\n",
       "                                             roxbury  \\\n",
       "0  ('n individuals who worked in finance  insuran...   \n",
       "1  ('Dr  Kenneth C  Edelin  whose historic 1975 m...   \n",
       "2  ('When they go up  they form the centerpiece o...   \n",
       "3  ('Good Morning Chief Justice Ireland  Presiden...   \n",
       "4  ('Good Morning Chief Justice Ireland  Presiden...   \n",
       "\n",
       "                                            mattapan  \\\n",
       "0  ('The public scrap over who will serve as the ...   \n",
       "1  ('In what police described as a horrific trage...   \n",
       "2  ('The fatal shooting today of a 9 year old Mat...   \n",
       "3  ('During a highly publicized Boston Police Dep...   \n",
       "4  ('At Greater Love Tabernacle Church today  mor...   \n",
       "\n",
       "                                           hyde_park  \\\n",
       "0  ('The Boston Police Department has issued a co...   \n",
       "1  ('nOn the weekend before he was to be sworn in...   \n",
       "2  ('Boston saw its first two homicides of 2014 o...   \n",
       "3  ('An elderly woman became Boston’s first fire ...   \n",
       "4  ('n officials in Boston want to give 4 500 mid...   \n",
       "\n",
       "                                              fenway  \\\n",
       "0  ('Wahlburgers  the burger joint owned by Dorch...   \n",
       "1  ('n n n    and  are expanding their burger bus...   \n",
       "2  ('Mayor Martin J  Walsh plans to set aside spa...   \n",
       "3  ('By last Christmas  Frank Nunes seemed to hav...   \n",
       "4  ('SALEM — Martha Coakley had already made the ...   \n",
       "\n",
       "                                         beacon_hill  \\\n",
       "0  ('Martin J  Walsh becomes the 48th mayor of Bo...   \n",
       "1  ('One bone chilling Saturday night about 11 mo...   \n",
       "2  ('nhe Boston Public Library is using three dim...   \n",
       "3  ('QUINCY — Massachusetts Democrats saw a new B...   \n",
       "4  ('The state’s highest court has thrown out the...   \n",
       "\n",
       "                                            downtown  \\\n",
       "0  ('Last week  Mayor Marty Walsh declared to the...   \n",
       "1  ('The Federal Reserve must take a “patient app...   \n",
       "2  ('ncooler buses  For decades  economists like ...   \n",
       "3  ('When Ari S  Heckman was growing up in Provid...   \n",
       "4  ('Marty Walsh had never met Arianna Huffington...   \n",
       "\n",
       "                                        south_boston  \\\n",
       "0  ('The 20 year old who allegedly beat a disable...   \n",
       "1  ('n and Michelle Wu stood side by side at the ...   \n",
       "2  ('Jack Conley  who grew up in South Boston and...   \n",
       "3  ('Mayor Martin J  Walsh said Wednesday that he...   \n",
       "4  ('The state’s largest gay rights organization ...   \n",
       "\n",
       "                                         east_boston  \\\n",
       "0  ('Saying that Massachusetts is facing “the big...   \n",
       "1  ('MEMPHIS — The thank yous were almost endless...   \n",
       "2  ('Marty Walsh has turned the casino licensing ...   \n",
       "3  ('Marty Walsh has turned the casino licensing ...   \n",
       "4  ('While he may not have been a household name ...   \n",
       "\n",
       "                                            back_bay  ...  \\\n",
       "0  ('First Night Boston almost didn’t happen this...  ...   \n",
       "1  ('Chances are  if you walked past the firehous...  ...   \n",
       "2  ('Stores selling luxury goods — once modest an...  ...   \n",
       "3  ('A midday altercation Friday in a bustling co...  ...   \n",
       "4  ('nn a brisk November morning in 2001  Hubert ...  ...   \n",
       "\n",
       "                                         charlestown  \\\n",
       "0  ('Bright skies belie the early spring chill as...   \n",
       "1  ('As neighbors living a world apart  they awok...   \n",
       "2  ('When Boston firefighters pulled up to a vaca...   \n",
       "3  ('Two Charlestown teenagers — a 14 year old gi...   \n",
       "4  ('A Charlestown man was sentenced to up to 12 ...   \n",
       "\n",
       "                                            brighton  \\\n",
       "0  ('Boston’s new mayor  Martin J  Walsh  has rep...   \n",
       "1  ('The 26 year old Chinese entrepreneur had jus...   \n",
       "2  ('It was just some children playing baseball o...   \n",
       "3  ('Boston police are asking for the public’s he...   \n",
       "4  ('noffice  Mayor Marty Walsh has properly focu...   \n",
       "\n",
       "                                             allston  \\\n",
       "0  ('A small army of city inspectors will soon be...   \n",
       "1  ('n n for help  The harrowing leaps from smoky...   \n",
       "2  ('n n for help  The harrowing leaps from smoky...   \n",
       "3  ('n n for help  The harrowing leaps from smoky...   \n",
       "4  ('Mayor Martin J  Walsh replaced on Monday the...   \n",
       "\n",
       "                                            west_end  \\\n",
       "0  ('Shakespeare’s “A Midsummer Night’s Dream” se...   \n",
       "1  ('nis here    the nascent organizing committee...   \n",
       "2  ('nis here    the nascent organizing committee...   \n",
       "3  ('The first thing everyone noticed about Dawnn...   \n",
       "4  ('Dawnn Jaffier  the 26 year old Brighton woma...   \n",
       "\n",
       "                                          roslindale  \\\n",
       "0  ('Last February  Brandon John joined more than...   \n",
       "1  ('Don’t ask how the sausage is made  the old s...   \n",
       "2  ('Former Boston councilor Felix D  Arroyo  the...   \n",
       "3  ('nn the middle of evening rush hour at South ...   \n",
       "4  ('nn the middle of evening rush hour at South ...   \n",
       "\n",
       "                                           north_end  \\\n",
       "0  ('When the  offered season ticket holders the ...   \n",
       "1  ('As America’s most Irish American city  it co...   \n",
       "2  ('In nine days  Wegmans will open a new superm...   \n",
       "3  ('n n n nThe 150 dancing  singing  and drummin...   \n",
       "4  ('“Maybe I need a psychiatrist ” says Donato F...   \n",
       "\n",
       "                                        mission_hill  \\\n",
       "0  ('They were immigrants from Iraq and India  th...   \n",
       "1  ('Beth Israel Deaconess Medical Center said We...   \n",
       "2  ('The Rev  Joseph Hung Duc Tran had been ordai...   \n",
       "3  ('nLittle about the ordinary looking two famil...   \n",
       "4  ('For 24 years  Ellen Wade and Maureen Brodoff...   \n",
       "\n",
       "                                      harbor_islands    longwood_medical_area  \\\n",
       "0  ('Rain crashes down on onto the tarp  thunder ...  ('no article', 'no_id')   \n",
       "1                            ('no article', 'no_id')  ('no article', 'no_id')   \n",
       "2                            ('no article', 'no_id')  ('no article', 'no_id')   \n",
       "3                            ('no article', 'no_id')  ('no article', 'no_id')   \n",
       "4                            ('no article', 'no_id')  ('no article', 'no_id')   \n",
       "\n",
       "                                        west_roxbury  \n",
       "0  ('It’s been almost a full month since Thomas M...  \n",
       "1  ('Mayor Martin J  Walsh’s pick for acting fire...  \n",
       "2  ('His cousin would come to Children’s Hospital...  \n",
       "3  ('The  is offering 15 percent off purchases fr...  \n",
       "4  ('A 33 year old man with a criminal record dat...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)\r\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84530ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(\"('no article', 'no_id')\")\r\n",
    "df['dorchester'] = df['dorchester'].apply(ast.literal_eval)\r\n",
    "df['roxbury'] = df['roxbury'].apply(ast.literal_eval)\r\n",
    "df['mattapan'] = df['mattapan'].apply(ast.literal_eval)\r\n",
    "df['hyde_park'] = df['hyde_park'].apply(ast.literal_eval)\r\n",
    "df['fenway'] = df['fenway'].apply(ast.literal_eval)\r\n",
    "df['beacon_hill'] = df['beacon_hill'].apply(ast.literal_eval)\r\n",
    "df['downtown'] = df['downtown'].apply(ast.literal_eval)\r\n",
    "df['south_boston'] = df['south_boston'].apply(ast.literal_eval)\r\n",
    "df['east_boston'] = df['east_boston'].apply(ast.literal_eval)\r\n",
    "df['back_bay'] = df['back_bay'].apply(ast.literal_eval)\r\n",
    "df['jamaica_plain'] = df['jamaica_plain'].apply(ast.literal_eval)\r\n",
    "df['south_end'] = df['south_end'].apply(ast.literal_eval)\r\n",
    "df['charlestown'] = df['charlestown'].apply(ast.literal_eval)\r\n",
    "df['brighton'] = df['brighton'].apply(ast.literal_eval)\r\n",
    "df['allston'] = df['allston'].apply(ast.literal_eval)\r\n",
    "df['west_end'] = df['west_end'].apply(ast.literal_eval)\r\n",
    "df['roslindale'] = df['roslindale'].apply(ast.literal_eval)\r\n",
    "df['north_end'] = df['north_end'].apply(ast.literal_eval)\r\n",
    "df['mission_hill'] = df['mission_hill'].apply(ast.literal_eval)\r\n",
    "df['harbor_islands'] = df['harbor_islands'].apply(ast.literal_eval)\r\n",
    "df['longwood_medical_area'] = df['longwood_medical_area'].apply(ast.literal_eval)\r\n",
    "df['west_roxbury'] = df['west_roxbury'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af556a68",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d66d02f104e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0marticle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0marticle\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'no article'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdocuments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocess' is not defined"
     ]
    }
   ],
   "source": [
    "documents = {'hyde_park': [], 'beacon_hill': [], 'south_boston': [], 'jamaica_plain': [], 'east_boston': [],\r\n",
    "                'south_end': [], 'back_bay': [], 'north_end': [], 'west_roxbury': [], 'mission_hill': [],\r\n",
    "                'harbor_islands': [], 'west_end': [], 'longwood_medical_area': [],\r\n",
    "                'dorchester': [], 'roxbury': [], 'downtown': [], 'fenway': [], 'mattapan': [], 'brighton': [],\r\n",
    "                'charlestown': [], 'roslindale': [], 'allston': []}\r\n",
    "\r\n",
    "for col in df.columns:\r\n",
    "    tokens = []\r\n",
    "    for i in range(df.shape[0]):\r\n",
    "        article, _ = df.loc[i][col]\r\n",
    "        if article != 'no article':\r\n",
    "            text = word_tokenize(preprocess(article))\r\n",
    "            tokens = tokens + text\r\n",
    "    documents[col] = tokens\r\n",
    "    print(col + ' DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7e07ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = []\r\n",
    "for key in documents:\r\n",
    "    processed_text.append(documents[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4cb88d65",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5f52d188",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = {}\r\n",
    "\r\n",
    "# keep track of how many neighborhoods' documents discuss a given token\r\n",
    "for i in range(len(df.columns)):\r\n",
    "    tokens = processed_text[i]\r\n",
    "    for w in tokens:\r\n",
    "        try:\r\n",
    "            DF[w].add(i)\r\n",
    "        except:\r\n",
    "            DF[w] = {i}\r\n",
    "\r\n",
    "for i in DF:\r\n",
    "    DF[i] = len(DF[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a44bc809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33882"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_vocab_size = len(DF)\r\n",
    "total_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eae36938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of documents in which this word occurs\r\n",
    "def doc_freq(word):\r\n",
    "    c = 0\r\n",
    "    try:\r\n",
    "        c = DF[word]\r\n",
    "    except:\r\n",
    "        pass\r\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a03150f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 0\r\n",
    "\r\n",
    "tf_idf = {}\r\n",
    "\r\n",
    "for i in range(len(df.columns)):\r\n",
    "    \r\n",
    "    # get all the tokenized text for a given neighborhood\r\n",
    "    tokens = processed_text[i]\r\n",
    "    \r\n",
    "    # count the number of times each token occurs in the text for a given neighborhood\r\n",
    "    counter = Counter(tokens)\r\n",
    "    \r\n",
    "    # get the total number of terms for a document (given neighborhood)\r\n",
    "    words_count = len(tokens)\r\n",
    "    \r\n",
    "    for token in np.unique(tokens):\r\n",
    "        \r\n",
    "        # compute term frequency\r\n",
    "        tf = counter[token] / words_count\r\n",
    "\r\n",
    "        # compute inverse document frequency\r\n",
    "        dfr = doc_freq(token)\r\n",
    "        idf = np.log((len(df.columns) + 1) / (dfr + 1))\r\n",
    "        \r\n",
    "        # compute tf-idf score\r\n",
    "        tf_idf[doc, token] = tf * idf\r\n",
    "\r\n",
    "    doc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cb24a0e6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d1598787",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1ddddc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_scores = {'dorchester': [], 'roxbury': [], 'mattapan': [], 'hyde_park': [], 'fenway': [],\r\n",
    "       'beacon_hill': [], 'downtown': [], 'south_boston': [], 'east_boston': [], 'back_bay': [],\r\n",
    "       'jamaica_plain': [], 'south_end': [], 'charlestown': [], 'brighton': [], 'allston': [],\r\n",
    "       'west_end': [], 'roslindale': [], 'north_end': [], 'mission_hill': [], 'harbor_islands': [],\r\n",
    "       'longwood_medical_area': [], 'west_roxbury': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "154af43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in tf_idf:\r\n",
    "    sub_ind, term = key\r\n",
    "    tf_idf_scores[subs[sub_ind]].append((term, tf_idf[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "454f2940",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in subs:\r\n",
    "    tf_idf_scores[col].sort(reverse=True)\r\n",
    "    temp = pd.DataFrame(tf_idf_scores[col], columns=['term', 'weight'])\r\n",
    "    temp = temp.sort_values(by=['weight'], ascending=False)\r\n",
    "    temp.to_csv('Yearly_TFIDF_Scores_by_Subneighborhood/2014/TFIDF_' + col + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c885a5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'west_roxbury'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d62edcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most imp words for a neighborhood using weights\r\n",
    "# look for similar words to most-important terms for each\r\n",
    "\r\n",
    "# most important terms here are the top 15-20 terms for a given neighborhood\r\n",
    "# across all years\r\n",
    "\r\n",
    "# check to see if duplicate articles exist; if those do, remove those\r\n",
    "\r\n",
    "# look at how similar TF-IDF results are for different neighborhoods\r\n",
    "# as well as the most-similar words\r\n",
    "\r\n",
    "# check if we get similar results from similar neighborhoods\r\n",
    "# are black and white distinctive, or are all unique, or \r\n",
    "# is there no clear pattern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "63ce4647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eventual goal is to assign topic to each article\r\n",
    "\r\n",
    "# when looking at tf-idf scores, if there is a clear trend\r\n",
    "# in the top words for a given neighborhood, that might be indicative\r\n",
    "# of the general topic associated with a neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4df043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "788c7a583b49e0f108948e9844ef083ea97a54690da4d8e91da56fd70fa16a57"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
